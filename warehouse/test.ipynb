{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc670b04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "SPARK_MASTER = \"spark://spark-master:7077\" \n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"PySparkML_Test\")\n",
    "    .master(SPARK_MASTER)\n",
    "    .getOrCreate()\n",
    ")\n",
    "print(f\"--- Spark Session démarrée et connectée au Master : {SPARK_MASTER} ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "data = [\n",
    "    (1.0, 5.0, 1.0),\n",
    "    (2.0, 6.0, 0.0),\n",
    "    (3.0, 7.0, 1.0),\n",
    "    (4.0, 8.0, 0.0),\n",
    "    (5.0, 9.0, 1.0),\n",
    "    (6.0, 4.0, 0.0),\n",
    "    (7.0, 3.0, 1.0),\n",
    "    (8.0, 2.0, 0.0),\n",
    "]\n",
    "columns = [\"feat_1\", \"feat_2\", \"label\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "print(\"Jeu de données initial:\")\n",
    "df.show()\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"feat_1\", \"feat_2\"], outputCol=\"features\")\n",
    "output = assembler.transform(df)\n",
    "\n",
    "training_data = output.select(\n",
    "    col(\"label\").cast(\"int\"),\n",
    "    col(\"features\")\n",
    ")\n",
    "print(\"Données prêtes pour le ML:\")\n",
    "training_data.show(truncate=False)\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "print(\"Démarrage de l'entraînement du modèle...\")\n",
    "\n",
    "lr_model = lr.fit(training_data)\n",
    "\n",
    "print(f\"Coefficient pour les features : {lr_model.coefficients}\")\n",
    "print(f\"Intercept : {lr_model.intercept}\")\n",
    "\n",
    "predictions = lr_model.transform(training_data)\n",
    "print(\"\\nPrédictions:\")\n",
    "predictions.select(\"label\", \"prediction\", \"probability\", \"features\").show(truncate=False)\n",
    "\n",
    "spark.stop()\n",
    "print(\"-\" * 50)\n",
    "print(\"Spark Session arrêtée.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
