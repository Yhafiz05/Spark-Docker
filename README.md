# Running Spark using Docker compose

Le principe du projet est de pouvoir faire tourner Spark sur un petit cluster constitu√© de quelque containers docker dans lesquels on aurait un master qui va coordonn√©e les noeuds worker.

---
# Spark

Spark est un framework open source qui permet de faire de l'analyse de donn√©es massives. C'est une solution beaucoup plus moderne que d'autre solutions comme **Hadoop MapReduce**.

---

## üí°Pourquoi Spark

- **Rapidit√©** : Spark effectue tous ses traitement en RAM au lieu d'√©crire sur le disque ce qui r√©duit les entr√©es sorties et le rend beaucoup plus rapide que ses pr√©d√©cesseurs. Cette structure stockant les donn√©es en ram est nomm√©e **RDD**.
- **API simple** : Spark est √† la base utilis√© avec du Scala mais il √©galement possible d'√©crire du code Python, Java ou R √† partir d'une api simple.
- **Traitement parall√®le** : Spark effectue les t√¢ches qu'on lui soumet en parall√®les sur plusieurs worker avec un syst√®me master/worker similaire ce que peut retrouver sur Hadoop (NameNode/DataNode).

## Comment fonctionne Spark
---
**Spark** se base sur une architecture Master/Worker :
- **Driver (master)** : contient le programme principal et planifie les t√¢ches.
- **Cluster Manager** : g√®re les ressources du cluster.
- **Worker** : ex√©cute les t√¢ches qui lui sont transmises via un executor et transmet le r√©sultat au master.

```mermaid
---
title: "Architecture Spark"
---
graph TD
    A["Spark Driver (Master)"] --> B["Cluster Manager (YARN / Mesos / Standalone)"]
    B --> W1["Worker Node 1"]
    B --> W2["Worker Node 2"]
    B --> W3["Worker Node 3"]

    subgraph W1
        E11["Executor 1+ Tasks"]
    end

    subgraph W2
        E21["Executor 2+ Tasks"]
    end

    subgraph W3
        E31["Executor 3+ Tasks"]
    end

    style A fill:#ffcc00,stroke:#333,stroke-width:2px
    style B fill:#ffd966,stroke:#333,stroke-width:1px
    style W1 fill:#d9ead3,stroke:#333,stroke-width:1px
    style W2 fill:#d9ead3,stroke:#333,stroke-width:1px
    style W3 fill:#d9ead3,stroke:#333,stroke-width:1px
    style E11 fill:#b6d7a8,stroke:#333,stroke-width:1px
    style E21 fill:#b6d7a8,stroke:#333,stroke-width:1px
    style E31 fill:#b6d7a8,stroke:#333,stroke-width:1px

```

---

# Docker

Docker est une plateforme de conteneurisation permettant de cr√©er, d√©ployer et ex√©cuter des applications dans des environnements isol√©s appel√©s **conteneurs**. Chaque conteneur embarque tout le n√©cessaire pour ex√©cuter l‚Äôapplication : code, biblioth√®ques, d√©pendances et configuration. Cela garantit un comportement identique, quel que soit l‚Äôenvironnement d‚Äôex√©cution.  

## Pourquoi utiliser Docker pour Spark

Pour un projet Spark, Docker pr√©sente plusieurs avantages :
- **Isolation** : chaque conteneur fonctionne ind√©pendamment, ce qui √©vite les conflits de d√©pendances.
- **Portabilit√©** : le cluster Spark fonctionne de la m√™me fa√ßon sur n‚Äôimporte quelle machine.
- **Reproductibilit√©** : l‚Äôenvironnement est d√©fini par un fichier (`docker-compose.yml`) garantissant que tout le monde utilise la m√™me configuration.
- **Scalabilit√©** : possibilit√© de monter ou descendre le nombre de workers facilement avec *docker-compose up --scale*.
- **Facilit√© de d√©ploiement** : Docker Compose orchestre plusieurs conteneurs (ma√Ætre + workers) via un seul fichier de configuration.
## Pourquoi docker compose

Docker compose est un outil pour d√©finir une application multi container. C'est un outil beaucoup utilis√© de nos jours pour un d√©ploiement efficace et rapide.

**Compose** simplifie le contr√¥le de toute l'architecture, rendant facile la gestion des services, r√©seaux et volumes dockers en un seul fichier sous format **YAML**.

En juste quelques commande il est possible de d√©ployer, de stopper , et de scaler une architecture :
- **docker compose up** : d√©ploie l'architecture.
- **docker compose down** : Stop toute une architecture.
- **docker-compose up --scale worker=5**: Pour scaler √† 5 container le service master. Il est aussi possible de d√©finir dans le **docker-compose.yml** une variable **replicas**.

```yaml title="Docker-compose avec replicas"
service:
  cache:
	image: redis:latest
	deploy:
	replicas: 2
```

